{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~ 40 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp dicom2tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read -> interpolate/resample -> crop-pad -> save (Requires pydicom=> 1.4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.medical.imaging_roi import *\n",
    "from fastai2.medical.imaging import dicom_windows\n",
    "from fastai2 import *\n",
    "from fastai2.torch_core import *\n",
    "from fastai2.core import *\n",
    "from fastai2.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = types.SimpleNamespace(\n",
    "    ATLAS_PATH = Path(\"/data/public/PICARE_BMETS_Raw_DICOM_Files\"),\n",
    "    MR_PATH = Path(\"/data/public/PICARE_SEGMENTATION_BRAINVENT_MR_V1\"),\n",
    "    CT_PATH = Path(\"/data/public/Training_CT_Raw_DICOM_Files\"),\n",
    "    MR_TEST2_PATH = Path(\"/data/public/Testing_MR_Raw_DICOM_Files\"),\n",
    "    CT_TEST2_PATH= Path(\"/data/public/Testing_CT_Raw_DICOM_Files\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ATLAS_PATH': PosixPath('/data/public/PICARE_BMETS_Raw_DICOM_Files'),\n",
       " 'MR_PATH': PosixPath('/data/public/PICARE_SEGMENTATION_BRAINVENT_MR_V1'),\n",
       " 'CT_PATH': PosixPath('/data/public/Training_CT_Raw_DICOM_Files'),\n",
       " 'MR_TEST2_PATH': PosixPath('/data/public/Testing_MR_Raw_DICOM_Files'),\n",
       " 'CT_TEST2_PATH': PosixPath('/data/public/Testing_CT_Raw_DICOM_Files')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paths.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.medical.imaging import DcmDataset, DcmMultiValue, _split_elem, _dcm2dict\n",
    "def _cast_dicom_special(x):\n",
    "    cls = type(x)\n",
    "    if not cls.__module__.startswith('pydicom'): return x\n",
    "    if cls.__base__ == object: return str(x)\n",
    "    return cls.__base__(x)\n",
    "@patch\n",
    "def as_dict2(self:DcmDataset, px_summ=True, multival=False):\n",
    "    pxdata = (0x7fe0,0x0010)\n",
    "    vals = [self[o] for o in self.keys() if o != pxdata]\n",
    "    its = [(v.keyword,v.value) for v in vals if not (not multival and isinstance(v.value,DcmMultiValue))]\n",
    "    res = dict(its)\n",
    "    res['fname'] = self.filename\n",
    "    for k,v in its: _split_elem(res,k,v)\n",
    "    for k in res: res[k] = _cast_dicom_special(res[k])\n",
    "    return res\n",
    "def _dcm2dict2(o): return o.dcmread().as_dict2(px_summ=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"/home/turgutluk/data/ventricles_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # create metadata csv file for each folder\n",
    "# paths = (\"ATLAS_PATH MR_PATH CT_PATH MR_TEST2_PATH CT_TEST2_PATH\").split()\n",
    "# for o in paths:\n",
    "#     PATH = data_paths.__dict__[o]\n",
    "#     all_dcm_files = get_files(PATH, extensions=['.dcm'])\n",
    "#     metadf = pd.DataFrame(parallel(_dcm2dict2, all_dcm_files))\n",
    "#     metadf.to_csv(DATA_PATH/f\"{o}_META.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/turgutluk/data/ventricles_data/csvs/CT_PATH_META.csv'),\n",
       " PosixPath('/home/turgutluk/data/ventricles_data/csvs/MR_PATH_META.csv'),\n",
       " PosixPath('/home/turgutluk/data/ventricles_data/csvs/MR_TEST2_PATH_META.csv'),\n",
       " PosixPath('/home/turgutluk/data/ventricles_data/csvs/CT_TEST2_PATH_META.csv'),\n",
       " PosixPath('/home/turgutluk/data/ventricles_data/csvs/ATLAS_PATH_META.csv')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvs = get_files(DATA_PATH, extensions=[\".csv\"]); list(csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT_PATH_META.csv 164\n",
      "MR_PATH_META.csv 150\n",
      "MR_TEST2_PATH_META.csv 20\n",
      "CT_TEST2_PATH_META.csv 20\n",
      "ATLAS_PATH_META.csv 2172\n"
     ]
    }
   ],
   "source": [
    "# get unique study instance in each folder\n",
    "for o in csvs: \n",
    "    df = pd.read_csv(o, low_memory=False)\n",
    "    print(o.name, len(np.unique(df['StudyInstanceUID'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_voxel_mask(image_ds_list, refid2masks):\n",
    "    voxel_mask = []\n",
    "    for img_ds in image_ds_list:\n",
    "        refid = img_ds[dicom_tags.sop_instance_uid].value\n",
    "        if refid in refid2masks: voxel_mask += [refid2masks[refid]]\n",
    "        else: voxel_mask += [torch.zeros(img_ds.shape, dtype=torch.uint8)]\n",
    "    voxel_mask = torch.stack(voxel_mask); voxel_mask.shape\n",
    "    return voxel_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def collect_study_datasets(dcm_datasets):\n",
    "    \"collect study datasets by study instance uid key\"\n",
    "    study_datasets = defaultdict(list)\n",
    "    for o in dcm_datasets: \n",
    "        if o.modality == dicom_modality.rtstruct: \n",
    "            study_datasets[o[dicom_tags.study_instance_uid].value].append(o)\n",
    "        elif o.modality in [dicom_modality.ct, dicom_modality.mr]: \n",
    "            study_datasets[o[dicom_tags.study_instance_uid].value].append(o)\n",
    "        else: raise Exception(f\"Unknown modality: {o.modality} in DcmDataset\")\n",
    "    return study_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def separate_instance_datasets(instance_datasets):\n",
    "    \"separate instance datasets into RTSTRUCT and image\"\n",
    "    struct_ds_list, image_ds_list = [],[]\n",
    "    for o in instance_datasets:\n",
    "        if o.modality == dicom_modality.rtstruct: \n",
    "            struct_ds_list.append(o)\n",
    "        elif o.modality in [dicom_modality.ct, dicom_modality.mr]:  \n",
    "            image_ds_list.append(o)\n",
    "    # pick first as struct ds\n",
    "    struct_ds = struct_ds_list[0]\n",
    "    return (struct_ds, image_ds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ROI = types.SimpleNamespace(brain=\"Brain\", ventricles=\"Ventricles\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def resample_voxel(x, scale_factor):\n",
    "    \"resamples 3D tensor x with scale_factor (z,y,x)\"\n",
    "    return F.interpolate(x[None,None,...].float(), scale_factor=scale_factor)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def center_crop_pad(x, targ_sz=(128,256,256)):\n",
    "    \"do center crop or pad to transform to targ_sz\"\n",
    "    x = x.clone()\n",
    "    targ_sz = array(targ_sz)\n",
    "    size = array(x.shape)\n",
    "    cnt = size//2\n",
    "    z1,x1,y1,z2,x2,y2 = (*cnt - targ_sz//2, *cnt + targ_sz//2)\n",
    "    if (x1 > 0) and (y1 > 0):       x = x[:,x1:x2,y1:y2]\n",
    "    elif (x1 > 0) and (y1 <= 0):    x = F.pad(x[:,x1:x2,:], (-y1,-y1))\n",
    "    elif (x1 <= 0) and (y1 > 0):    x = F.pad(x[:,:,y1:y2], (0,0,-x1,-x1))\n",
    "    else:                           x = F.pad(x, (-y1,-y1,-x1,-x1)) \n",
    "   \n",
    "    if z1 > 0: x = x[z1:z2]\n",
    "    else: x = F.pad(x, (0,0,0,0,-z1,-z1))\n",
    "    \n",
    "    if list(x.shape) != list(targ_sz):\n",
    "        resz, resy, resx = array(x.shape) - array(targ_sz)\n",
    "        if resx == 1: x = x[:,:,1:]\n",
    "        elif resx == -1: x = F.pad(x, (0,1))\n",
    "            \n",
    "        if resy == 1: x = x[:,1:,:]\n",
    "        elif resy == -1: x = F.pad(x, (0,0,0,1))\n",
    "        \n",
    "        if resz == 1: x = x[1:,:,:]\n",
    "        elif resz == -1: x = F.pad(x, (0,0,0,0,0,1))\n",
    "    \n",
    "    try:\n",
    "        assert list(x.shape) == list(targ_sz)\n",
    "    except:\n",
    "        raise Exception(x.shape)\n",
    "    finally:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_and_save_img_mask(instance_datasets, output_path, resample_to=(1,1,3)):\n",
    "    \"save image and masks of a single study instance\"\n",
    "    struct_ds, image_ds_list = separate_instance_datasets(instance_datasets)\n",
    "    study_instance_uid = struct_ds[dicom_tags.study_instance_uid].value\n",
    "    if (ROI.brain not in struct_ds.roi_names) and (ROI.ventricles not in struct_ds.roi_names): return\n",
    "    brain_contour_refdict = struct_ds.contour_refdict(ROI.brain)\n",
    "    ventricles_contour_refdict = struct_ds.contour_refdict(ROI.ventricles)\n",
    "\n",
    "    # image voxel\n",
    "    refid2img_ds = {img_ds[dicom_tags.sop_instance_uid].value:img_ds for img_ds in image_ds_list}\n",
    "    image_ds_list = sorted(image_ds_list, key=lambda o: int(o['InstanceNumber'].value))\n",
    "    voxel_image = torch.stack([img_ds.windowed(*dicom_windows.brain) if img_ds.modality == dicom_modality.ct\n",
    "                               else img_ds.pixels for img_ds in image_ds_list])\n",
    "\n",
    "    # brain mask voxel\n",
    "    refid2masks = {}\n",
    "    for refid, contourdata in brain_contour_refdict.items(): \n",
    "        ref_ds = refid2img_ds[refid]\n",
    "        refid2masks[refid] = tensor(sum([ref_ds.contourdata2mask(o) for o in contourdata]).astype(np.uint8))\n",
    "    brain_voxel_mask = create_voxel_mask(image_ds_list, refid2masks)\n",
    "\n",
    "    # ventricles mask voxel\n",
    "    refid2masks = {}\n",
    "    for refid, contourdata in ventricles_contour_refdict.items(): \n",
    "        ref_ds = refid2img_ds[refid]\n",
    "        refid2masks[refid] = tensor(sum([ref_ds.contourdata2mask(o) for o in contourdata]).astype(np.uint8))\n",
    "    ventricles_voxel_mask = create_voxel_mask(image_ds_list, refid2masks)\n",
    "        \n",
    "    # resample\n",
    "    if resample_to is not None:\n",
    "        image_ds = image_ds_list[0] # pick one image dataset for metadata\n",
    "        scale_factor = image_ds.spacings[::-1] # z,y,x\n",
    "        voxel_image = resample_voxel(voxel_image, scale_factor) \n",
    "        brain_voxel_mask = resample_voxel(brain_voxel_mask, scale_factor).byte()\n",
    "        ventricles_voxel_mask = resample_voxel(ventricles_voxel_mask, scale_factor).byte()\n",
    "    \n",
    "    # save image and masks by study instance uid\n",
    "    torch.save(voxel_image, output_path/f\"{study_instance_uid}_image.pt\")\n",
    "    torch.save(brain_voxel_mask, output_path/f\"{study_instance_uid}_brain_mask.pt\")\n",
    "    torch.save(ventricles_voxel_mask, output_path/f\"{study_instance_uid}_ventricles_mask.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_study(study, output_path, **kwargs):\n",
    "    try:\n",
    "        dcm_files = get_files(study, extensions=['.dcm'])\n",
    "        dcm_datasets = (o.dcmread() for o in dcm_files)\n",
    "        study_datasets = collect_study_datasets(dcm_datasets)\n",
    "        study_datasets = list((study_datasets).values())\n",
    "        # save each instance in this study\n",
    "        f = partial(create_and_save_img_mask, output_path=output_path, **kwargs)\n",
    "        for o in study_datasets: f(o)\n",
    "            \n",
    "    except Exception as e:  \n",
    "        print(f\"{e}, study: {study}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def _crop_pad_save(o, targ_sz):\n",
    "    try:\n",
    "        x = torch.load(o)\n",
    "        x = center_crop_pad(x, targ_sz)\n",
    "        torch.save(x, o)\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test: read-interpolate-save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output: ATLAS, MR, CT\n",
    "input_path = data_paths.MR_PATH\n",
    "studies = input_path.ls()\n",
    "output_path = Path(\"/home/turgutluk/data/ventricles_data/mr\")\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "study = studies[0]\n",
    "save_study(study, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'FileDataset' object has no attribute 'PixelData', study: /data/public/PICARE_SEGMENTATION_BRAINVENT_MR_V1/2014-04__Studies\n",
      "CPU times: user 215 ms, sys: 287 ms, total: 502 ms\n",
      "Wall time: 1min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#107) [None,None,None,None,None,None,None,None,None,None...]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# decrease n_workers to have enough resources - maybe colliding with get_files?\n",
    "# ATLAS: 15 mins with resample n_workers=defaults.cpus//4\n",
    "# MR: 2 mins create, interpolate, crop-pad\n",
    "# CT: 3 min with resample n_workers=defaults.cpus//4\n",
    "f = partial(save_study, output_path=output_path)\n",
    "parallel(f, studies, n_workers=defaults.cpus//4)\n",
    "# for o in studies: f(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test: crop-pad save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#444) [/home/turgutluk/data/ventricles_data/mr/2.16.840.1.114362.1.11741058.21988995044.484791583.866.8004_brain_mask.pt,/home/turgutluk/data/ventricles_data/mr/2.16.840.1.114362.1.11741058.21988995044.486778702.402.1956_brain_mask.pt,/home/turgutluk/data/ventricles_data/mr/2.16.840.1.114362.1.11741058.21988995044.484728780.561.7428_image.pt,/home/turgutluk/data/ventricles_data/mr/2.16.840.1.114362.1.11741058.21988995044.486780005.568.3239_ventricles_mask.pt,/home/turgutluk/data/ventricles_data/mr/2.16.840.1.114362.1.11741058.21988995044.486780130.437.3363_ventricles_mask.pt,/home/turgutluk/data/ventricles_data/mr/2.16.840.1.114362.1.11741058.21988995044.484813575.357.1955_brain_mask.pt,/home/turgutluk/data/ventricles_data/mr/2.16.840.1.114362.1.11741058.21988995044.486777591.560.1478_image.pt,/home/turgutluk/data/ventricles_data/mr/2.16.840.1.114362.1.11741058.21988995044.484726697.604.2580_brain_mask.pt,/home/turgutluk/data/ventricles_data/mr/2.16.840.1.114362.1.11741058.21988995044.486777965.262.1656_ventricles_mask.pt,/home/turgutluk/data/ventricles_data/mr/2.16.840.1.114362.1.11741058.21988995044.484727073.525.5003_image.pt...]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_files(output_path, extensions=['.pt']); files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([186, 259, 259])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(np.random.choice(files)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#444) [None,None,None,None,None,None,None,None,None,None...]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ_sz=(128,256,256)\n",
    "f = partial(_crop_pad_save, targ_sz=targ_sz)\n",
    "parallel(f, files, n_workers=defaults.cpus//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for o in files: list(torch.load(o).shape) == [128,256,256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import yaml\n",
    "with open(os.environ.get('YAML_PATH', '../data.yaml')) as f: io = yaml.load(f.read(), yaml.FullLoader)\n",
    "\n",
    "input_paths = types.SimpleNamespace(\n",
    "    ATLAS_PATH=io['input']['ATLAS_PATH'],\n",
    "    MR_PATH=io['input']['MR_PATH'],\n",
    "    CT_PATH=io['input']['CT_PATH'],\n",
    "    MR_TEST2_PATH=io['input']['MR_TEST2_PATH'],\n",
    "    CT_TEST2_PATH=io['input']['CT_TEST2_PATH'],\n",
    ")\n",
    "\n",
    "output_paths = types.SimpleNamespace(\n",
    "    ATLAS=io['output']['ATLAS'],\n",
    "    MR=io['output']['MR'],\n",
    "    CT=io['output']['CT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from time import perf_counter\n",
    "@call_parse\n",
    "def main(input_path:Param(\"Data to prepare\", str),\n",
    "         output_path:Param(\"Data to prepare\", str),\n",
    "         resample_to:Param(\"Resample dimensions in mm\", tuple)=(1,1,3),\n",
    "         targ_sz:Param(\"Final crop pad dimensions\", tuple)=(128,256,256)\n",
    "        ):\n",
    "    \"Read DICOM from input_path and save image-mask tensors to output_path\"\n",
    "\n",
    "    start = perf_counter()\n",
    "    \n",
    "    # get input and output paths\n",
    "    input_path, output_path = input_paths.__dict__[input_path], output_paths.__dict__[output_path]\n",
    "    input_path, output_path = Path(input_path), Path(output_path)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    print(f\"reading from {str(input_path)}\\nwriting to {str(output_path)}\")\n",
    "   \n",
    "    # read, interpolate\n",
    "    print(\"Read, create, interpolate and save\")\n",
    "    studies = input_path.ls()\n",
    "    f = partial(save_study, output_path=output_path, resample_to=resample_to)\n",
    "    parallel(f, studies, n_workers=defaults.cpus//4)\n",
    "    \n",
    "    # crop - pad and save\n",
    "    print(\"Read, crop-pad and save\")\n",
    "    files = get_files(output_path, extensions=['.pt'])\n",
    "    f = partial(_crop_pad_save, targ_sz=targ_sz)\n",
    "    parallel(f, files, n_workers=defaults.cpus//4)\n",
    "    \n",
    "    end = perf_counter()\n",
    "    print(f\"Total time taken {end-start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 1a) dicom to tensor.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from local.notebook.export import notebook2script\n",
    "notebook2script(\"1a) dicom to tensor.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python ../dev/local/data_prep.py --input_path_name=MR_PATH --output_path=/home/turgutluk/data/ventricles_data/mr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _plot_voxel(voxel):\n",
    "    n = int(np.ceil(np.sqrt(len(voxel))))\n",
    "    fig,axes = plt.subplots(n,n,figsize=(4*n,4*n))\n",
    "    for i,(arr,ax) in enumerate(zip(voxel,axes.flatten())): \n",
    "        ax.imshow(arr); ax.set_title(str(i)); ax.set_xticks([]); ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('/home/turgutluk/data/ventricles_data/ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_and_masks = output_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#483) [/home/turgutluk/data/ventricles_data/ct/2.16.840.1.114362.1.11741058.21988995044.484454177.212.2316_image.pt,/home/turgutluk/data/ventricles_data/ct/2.16.840.1.114362.1.11738497.21988995044.484202340.904.3109_brain_mask.pt,/home/turgutluk/data/ventricles_data/ct/2.16.840.1.114362.1.11741058.21988995044.484710844.648.4407_brain_mask.pt,/home/turgutluk/data/ventricles_data/ct/2.16.840.1.114362.1.11741058.21988995044.484709190.636.3727_ventricles_mask.pt,/home/turgutluk/data/ventricles_data/ct/2.16.840.1.114362.1.11741058.21988995044.484707938.102.7130_image.pt,/home/turgutluk/data/ventricles_data/ct/2.16.840.1.114362.1.11738497.21988995044.484202177.1001.522_ventricles_mask.pt,/home/turgutluk/data/ventricles_data/ct/2.16.840.1.114362.1.11738497.21988995044.484202252.587.1861_brain_mask.pt,/home/turgutluk/data/ventricles_data/ct/2.16.840.1.114362.1.11741058.21988995044.484455026.733.2368_image.pt,/home/turgutluk/data/ventricles_data/ct/2.16.840.1.114362.1.11741058.21988995044.484451915.687.409_ventricles_mask.pt,/home/turgutluk/data/ventricles_data/ct/2.16.840.1.114362.1.11741058.21988995044.484447075.467.164_image.pt...]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_and_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_instance_uids = images_and_masks.map(lambda o: o.name.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c25b5d8c50452b9219f0967d6f46d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=483), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(torch.Size([128, 256, 256]), 483)]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract tensor size counts\n",
    "from tqdm.notebook import tqdm\n",
    "sizes = []\n",
    "for suid in tqdm(study_instance_uids): \n",
    "    img = torch.load(output_path/f\"{suid}_brain_mask.pt\")\n",
    "    size = img.shape\n",
    "    sizes.append(size)\n",
    "size_counts = Counter(sizes)\n",
    "size_counts.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 256, 256]),\n",
       " torch.Size([128, 256, 256]),\n",
       " torch.Size([128, 256, 256]))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suid = np.random.choice(study_instance_uids)\n",
    "voxel_image = torch.load(output_path/f\"{suid}_image.pt\")\n",
    "brain_voxel_mask = torch.load(output_path/f\"{suid}_brain_mask.pt\")\n",
    "ventricles_voxel_mask = torch.load(output_path/f\"{suid}_ventricles_mask.pt\")\n",
    "voxel_image.shape, brain_voxel_mask.shape, ventricles_voxel_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.920478e+06, 7.336700e+05, 1.425108e+06, 1.767780e+05,\n",
       "        8.648900e+04, 3.669200e+04, 7.915000e+03, 1.273000e+03,\n",
       "        1.850000e+02, 2.000000e+01]),\n",
       " array([   0. ,  733.3, 1466.6, 2199.9, 2933.2, 3666.5, 4399.8, 5133.1,\n",
       "        5866.4, 6599.7, 7333. ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(voxel_image.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_voxel(voxel_image[:, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_voxel(brain_voxel_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_voxel(ventricles_voxel_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai_dev]",
   "language": "python",
   "name": "conda-env-fastai_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
