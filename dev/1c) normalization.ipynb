{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~ 7 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize image and skull_stripped_image for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.medical.imaging_roi import *\n",
    "from fastai2.medical.imaging import dicom_windows\n",
    "from fastai2 import *\n",
    "from fastai2.torch_core import *\n",
    "from fastai2.core import *\n",
    "from fastai2.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.data_prep import _plot_voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['YAML_DATA']=\"/home/turgutluk/Vent_Seg_Project/dev/data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient Position Attribute - https://dicom.innolitics.com/ciods/raw-data/general-series/00185100\n",
    "# We don't normalize it by patient position and leave it as original\n",
    "# This in a way acts as an inherent data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images with mean std normalization at every pixel\n",
    "# Normalize skull stripped images with mean std calculated inside brain region, \n",
    "# set non-brain region as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _normalize(t, mean, std):\n",
    "    \"normalization func\"\n",
    "    t = torch.clamp((t - mean) / std, -5, 5)\n",
    "    _min, _max = torch.min(t), torch.max(t)\n",
    "    return (t - _min) / (_max - _min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _normalize_images_and_save(o):\n",
    "    \"Normalizes individual images to 0-1 scale and save\"\n",
    "    # read image\n",
    "    t = torch.load(o)\n",
    "    # normalize\n",
    "    std,mean = torch.std_mean(t)\n",
    "    t = _normalize(t, mean, std)\n",
    "    # save\n",
    "    p = o.parent\n",
    "    suid = o.name.split('_')[0]\n",
    "    torch.save(t, p/f\"{suid}_image_normalized.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalized skull stripped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _normalize_skull_stripped_images_and_save(o):\n",
    "    \"Normalizes individual skull stripped images to 0-1 scale and save\"\n",
    "    # read image and mask\n",
    "    t = torch.load(o)\n",
    "    p = o.parent\n",
    "    suid = o.name.split('_')[0]\n",
    "    msk = torch.load(p/f\"{suid}_brain_mask.pt\")\n",
    "    # normalize\n",
    "    std,mean = torch.std_mean(t[msk.bool()])\n",
    "    t = _normalize(t, mean, std)*msk\n",
    "    # save\n",
    "    torch.save(t, p/f\"{suid}_skull_stripped_image_normalized.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test: normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"/home/turgutluk/data/ventricles_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files(output_path, extensions=['.pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [o for o in files if ('image' in o.name) and ('skull' not in o.name)]\n",
    "skull_stripped_image_files = [o for o in files if ('image' in o.name) and ('skull' in o.name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2501, 2501)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_files), len(skull_stripped_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2501) [None,None,None,None,None,None,None,None,None,None...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 mins\n",
    "parallel(_normalize_images_and_save, image_files, n_workers=defaults.cpus//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2501) [None,None,None,None,None,None,None,None,None,None...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 mins\n",
    "parallel(_normalize_skull_stripped_images_and_save, skull_stripped_image_files, n_workers=defaults.cpus//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "import yaml\n",
    "with open(os.environ.get('YAML_DATA', '../data.yaml')) as f: io = yaml.load(f.read(), yaml.FullLoader)\n",
    "\n",
    "output_paths = types.SimpleNamespace(\n",
    "    ATLAS=io['output']['ATLAS'],\n",
    "    MR=io['output']['MR'],\n",
    "    CT=io['output']['CT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from time import perf_counter\n",
    "@call_parse\n",
    "def main(output_path:Param(\"Directory that have data prep results\", str)):\n",
    "    \"Read tensors, normalize images and skull stripped images\"\n",
    "    start = perf_counter()\n",
    "    \n",
    "    output_path = Path(output_paths.__dict__[output_path])\n",
    "    files = get_files(output_path, extensions=['.pt'])\n",
    "    image_files = [o for o in files if ('image' in o.name) and ('skull' not in o.name)]\n",
    "    skull_stripped_image_files = [o for o in files if ('image' in o.name) and ('skull' in o.name)]\n",
    "    parallel(_normalize_images_and_save, image_files, n_workers=defaults.cpus//2)\n",
    "    parallel(_normalize_skull_stripped_images_and_save, skull_stripped_image_files, n_workers=defaults.cpus//2)\n",
    "    \n",
    "    end = perf_counter()\n",
    "    print(f\"Total time taken {end-start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 1c) normalization.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from local.notebook.export import notebook2script\n",
    "notebook2script(\"1c) normalization.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai_dev]",
   "language": "python",
   "name": "conda-env-fastai_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
