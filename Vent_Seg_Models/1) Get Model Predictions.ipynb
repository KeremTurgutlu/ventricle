{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model predictions for best models trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.script import *\n",
    "\n",
    "from data_utils import *\n",
    "from models import *\n",
    "from learn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['notl_brain_mr', 'notl_brain_ct', 'atlas_brain_mr', 'notl_ventricle_mr', 'notl_ventricle_ct', 'atlas_ventricle_mr'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the datasets: \n",
    "\n",
    "- **MR_Dataset (Brain):** `notl_brain_mr`\n",
    "- **CT_Dataset (Brain):** `notl_brain_ct`,\n",
    "- **MR_Dataset (Ventricle):** `notl_ventricle_mr`,\n",
    "- **CT_Dataset (Ventricle):** `notl_ventricle_ct`\n",
    "- **Atlas_Dataset (Brain):** `atlas_brain_mr`\n",
    "- **Atlas_Dataset (Ventricle):** `atlas_ventricle_mr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'notl_brain_mr'\n",
    "f = data_dict[data_name]\n",
    "train_paths, valid_paths, test1_paths, test2_paths = f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MRI_3D_Dataset(*train_paths)\n",
    "valid_ds = MRI_3D_Dataset(*valid_paths)\n",
    "test1_ds = MRI_3D_Dataset(*test1_paths) if test1_paths else None\n",
    "test2_ds = MRI_3D_Dataset(*test2_paths) if test2_paths else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "data = DataBunch.create(train_ds=train_ds, valid_ds=valid_ds, bs=bs)\n",
    "test1_dl = DeviceDataLoader(DataLoader(test1_ds, batch_size=bs), device=data.device) if test1_ds else None\n",
    "test2_dl = DeviceDataLoader(DataLoader(test2_ds, batch_size=bs), device=data.device) if test2_ds else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'baseline6'\n",
    "f = experiment_model_dict[model_name]; m = f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test2_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the model types: \n",
    "\n",
    "- **MR_Dataset (Brain) NOTL :** `notl_brain_mr_models`\n",
    "- **MR_Dataset (Brain) TL :** `tl_brain_mr_models`\n",
    "\n",
    "- **CT_Dataset (Brain) NOTL:** `notl_brain_ct_models`,\n",
    "- **CT_Dataset (Brain) TL:** `tl_brain_ct_models`,\n",
    "\n",
    "- **MR_Dataset (Ventricle) NOTL:** `notl_ventricle_mr_models`,\n",
    "- **MR_Dataset (Ventricle) TL:** `tl_ventricle_mr_models`,\n",
    "\n",
    "- **CT_Dataset (Ventricle) NOTL:** `notl_ventricle_ct_models`\n",
    "- **CT_Dataset (Ventricle) TL:** `tl_ventricle_ct_models`\n",
    "\n",
    "- **Atlas_Dataset (Brain):** `atlas_brain_mr_models`\n",
    "\n",
    "- **Atlas_Dataset (Ventricle):** `atlas_ventricle_mr_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = 'dice'\n",
    "model_dir = 'notl_brain_mr_models'\n",
    "#model_dir = '../Vent_Seg_Models/notl_brain_mr_models/best_of_NOTL_Brain_MR_Baseline_6.pth'\n",
    "learn = Learner(data=data, model=m, callbacks=[], callback_fns=[], model_dir=model_dir)\n",
    "learn.loss_func = {'dice':dice_loss, 'bce':BCEWithLogitsFlat(), 'mixed':None}[loss_func] \n",
    "learn.metrics = [dice_score]\n",
    "learn.to_fp16();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('notl_brain_mr_models/best_of_NOTL_Brain_MR_Baseline_6.pth'),\n",
       " PosixPath('notl_brain_mr_models/final_of_NOTL_Brain_MR_Baseline_6.pth')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(sorted((learn.path/learn.model_dir).ls(), key=lambda o:int(o.stem.split('_')[-1])))\n",
    "except:\n",
    "    (display((learn.path/learn.model_dir).ls()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=DataBunch;\n",
       "\n",
       "Train: <data_utils.MRI_3D_Dataset object at 0x7f9b1990dc50>;\n",
       "\n",
       "Valid: <data_utils.MRI_3D_Dataset object at 0x7f9b1990dc10>;\n",
       "\n",
       "Test: None, model=MeshNet(\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "      (3): Dropout3d(p=0)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "      (3): Dropout3d(p=0)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "      (3): Dropout3d(p=0)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "      (3): Dropout3d(p=0)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2))\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "      (3): Dropout3d(p=0)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4))\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "      (3): Dropout3d(p=0)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(8, 8, 8), dilation=(8, 8, 8))\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "      (3): Dropout3d(p=0)\n",
       "    )\n",
       "    (7): Conv3d(8, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<function dice_loss at 0x7f9b1995a830>, metrics=[<function dice_score at 0x7f9b1995a710>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='notl_brain_mr_models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (1): PReLU(num_parameters=1)\n",
       "  (2): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "  (3): Dropout3d(p=0)\n",
       "  (4): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (5): PReLU(num_parameters=1)\n",
       "  (6): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "  (7): Dropout3d(p=0)\n",
       "  (8): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (9): PReLU(num_parameters=1)\n",
       "  (10): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "  (11): Dropout3d(p=0)\n",
       "  (12): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (13): PReLU(num_parameters=1)\n",
       "  (14): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "  (15): Dropout3d(p=0)\n",
       "  (16): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2))\n",
       "  (17): PReLU(num_parameters=1)\n",
       "  (18): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "  (19): Dropout3d(p=0)\n",
       "  (20): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4))\n",
       "  (21): PReLU(num_parameters=1)\n",
       "  (22): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "  (23): Dropout3d(p=0)\n",
       "  (24): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(8, 8, 8), dilation=(8, 8, 8))\n",
       "  (25): PReLU(num_parameters=1)\n",
       "  (26): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "  (27): Dropout3d(p=0)\n",
       "  (28): Conv3d(8, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn.load('best_of_TL_Ventricle_CT_Baseline_11');\n",
    "learn.load('best_of_NOTL_Brain_MR_Baseline_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.067283615, tensor(0.9348)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate(learn.data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fp32();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.058079354, tensor(0.9443)]\n"
     ]
    }
   ],
   "source": [
    "if test1_dl: print(learn.validate(test1_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10087112, tensor(0.9013)]\n"
     ]
    }
   ],
   "source": [
    "if test2_dl: print(learn.validate(test2_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# path = Path(\"logs/\"); path.ls()\n",
    "\n",
    "# path = Path(f\"logs/{model_dir}\"); path.ls()\n",
    "\n",
    "# log_df = pd.read_csv(path/'ATLAS_Brain_MR_Baseline_11.csv')\n",
    "\n",
    "# log_df\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "# ax.set_title(f'Loss: {loss_func}')\n",
    "# ax.set_xlabel(\"Epoch\")\n",
    "# ax.plot(log_df['train_loss'])\n",
    "# ax.plot(log_df['valid_loss']);\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "# ax.set_title(f\"Dice Score: {np.round(log_df['dice_score'].max(), 2)}\")\n",
    "# ax.set_xlabel(\"Epoch\")\n",
    "# plt.plot(log_df['dice_score']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def to_int8(a): return a.astype(np.uint8)\n",
    "\n",
    "# data1 = DataBunch.create(train_ds=train_ds, valid_ds=valid_ds, test_ds=test1_ds, bs=3)\n",
    "# data2 = DataBunch.create(train_ds=train_ds, valid_ds=valid_ds, test_ds=test2_ds, bs=3)\n",
    "\n",
    "# train_fnames = data1.train_ds.img_fnames\n",
    "# valid_fnames = data1.valid_ds.img_fnames\n",
    "# test1_fnames = data1.test_ds.img_fnames\n",
    "# test2_fnames = data1.test_ds.img_fnames\n",
    "\n",
    "# len(train_fnames), len(valid_fnames), len(test1_fnames), len(test2_fnames)\n",
    "\n",
    "# train_dl = data1.train_dl.new(shuffle=False)\n",
    "# valid_dl = data1.valid_dl.new(shuffle=False)\n",
    "# test1_dl = data1.test_dl.new(shuffle=False)\n",
    "# test2_dl = data2.test_dl.new(shuffle=False)\n",
    "\n",
    "# learn.to_fp16();\n",
    "\n",
    "# # # training\n",
    "# # images, preds, masks = get_img_pred_masks(learn, train_dl)\n",
    "\n",
    "# # # validation\n",
    "# # images, preds, masks = get_img_pred_masks(learn, valid_dl)\n",
    "\n",
    "# # # test1\n",
    "# # images, preds, masks = get_img_pred_masks(learn, test1_dl)\n",
    "\n",
    "# # # test2\n",
    "# # images, preds, masks = get_img_pred_masks(learn, test2_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Deep Learning with Atlas\n",
    "\n",
    "Skull strip train, valid, test1 and test2\n",
    "\n",
    "- Compare with atlas masks\n",
    "- RuntimeError: _th_cat is not implemented for type torch.HalfTensor\n",
    "- Save to data_path/**/skull_stripped_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_targs(dl):\n",
    "    test_preds, test_targs = get_preds(learn.model, dl)\n",
    "    test_preds.squeeze_(1); test_preds.sigmoid_();\n",
    "    return test_preds, test_targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_preds, test1_targs = get_preds_targs(test1_dl)\n",
    "test2_preds, test2_targs = get_preds_targs(test2_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 128, 256, 256]), torch.Size([15, 128, 256, 256]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_preds.shape, test1_targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 128, 256, 256]), torch.Size([20, 128, 256, 256]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_preds.shape, test2_targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(10,20))\n",
    "ImageSegment(test1_preds[0][60][None,...]).show(ax=ax[0], alpha=1, cmap='tab20', title='pred')\n",
    "ImageSegment(test1_targs[0][60][None,...]).show(ax=ax[1], alpha=1, cmap='tab20', title='targ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(\"/home/turgutluk/data/Segmentation_Dataset/CT_Dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_savedir = save_path/'test1/ventricle_preds'; os.makedirs(test1_savedir, exist_ok=True)\n",
    "test2_savedir = save_path/'test2/ventricle_preds'; os.makedirs(test2_savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle([test1_preds, test1_targs], test1_savedir/f'{model_name}_preds.pkl')\n",
    "pd.to_pickle([test2_preds, test2_targs], test2_savedir/f'{model_name}_preds.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skull Stripping v2\n",
    "\n",
    "- Human annotated brain masks will be used where possible\n",
    "- \"First, we normalize each modality of each patient independently by subtracting the mean and dividing by the standard deviation of the brain region. We then clip the resulting images at [−5, 5] to remove outliers and subsequently rescale to [0, 1], with the non-brain region being set to 0.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dataset = 'MR_Dataset_Atlas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_path/f'{parent_dataset}/train/skull_stripped_v2', exist_ok=True)\n",
    "os.makedirs(data_path/f'{parent_dataset}/validation/skull_stripped_v2', exist_ok=True)\n",
    "if test1_ds: os.makedirs(data_path/f'{parent_dataset}/test1/skull_stripped_v2', exist_ok=True) \n",
    "if test2_ds: os.makedirs(data_path/f'{parent_dataset}/test2/skull_stripped_v2', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../data/Segmentation_Dataset/MR_Dataset_Atlas/train/raw_images/BrainMets-UCSF-00001_19990425000000.000_2.16.840_579.6972_RTst_1999-04-25_000000_._MR.Bias.Corrected,.axial.t1.g_n1__00000_MR.npy'),\n",
       " PosixPath('../../data/Segmentation_Dataset/MR_Dataset_Atlas/train/raw_images/BrainMets-UCSF-00004_19970413000000.000_2.16.840_482.7049_RTst_1997-04-13_000000_._MR.Bias.Corrected,.axial_n1__00000_MR.npy')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((data_path/f'{parent_dataset}/train/raw_images').ls())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../data/Segmentation_Dataset/MR_Dataset_Atlas/train/brain_atlas/BrainMets-UCSF-00001_19990425000000.000_2.16.840_579.6972_RTst_1999-04-25_000000_._MR.Bias.Corrected,.axial.t1.g_n1__00000_MR.npy'),\n",
       " PosixPath('../../data/Segmentation_Dataset/MR_Dataset_Atlas/train/brain_atlas/BrainMets-UCSF-00004_19970413000000.000_2.16.840_482.7049_RTst_1997-04-13_000000_._MR.Bias.Corrected,.axial_n1__00000_MR.npy')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((data_path/f'{parent_dataset}/train/brain_atlas').ls())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_images = [np.load(fn) for fn in (data_path/f'{parent_dataset}/train/raw_images').ls()]\n",
    "# # brain_masks = [np.load(fn) for fn in (data_path/f'{parent_dataset}/train/brain_masks').ls()]\n",
    "# brain_masks = [np.load(fn) for fn in (data_path/f'{parent_dataset}/train/brain_atlas').ls()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(raw_images), len(brain_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pixel density plot of different scans\n",
    "for i in range(10):\n",
    "    sns.distplot(np.clip(raw_images[i][50:70].flatten(), 0, 400), hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_with_mask(image, mask):\n",
    "    \"\"\"\n",
    "    First, we normalize each modality of each patient \n",
    "    independently by subtracting the mean and dividing by the standard deviation of the brain region.\n",
    "    We then clip the resulting images at [−5, 5] to remove outliers and subsequently rescale to [0, 1],\n",
    "    with the non-brain region being set to 0.\n",
    "    \"\"\"\n",
    "    mx = np.ma.masked_array(image, mask=1-mask) # True for places that are masked, we want to exclude non-brain\n",
    "    mean, std = mx.mean(), mx.std()\n",
    "    return np.clip((image - mean) / std, -5, 5)*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_samples = [normalize_with_mask(image, mask) for image, mask in zip(raw_images[:10], brain_masks[:10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel density plot of normalized scans\n",
    "for i in range(10):\n",
    "    sns.distplot(np.clip(normalized_samples[i][50:70].flatten(), -2, 2), hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize=(15,6))\n",
    "for i,ax in enumerate(axes.flatten()): ax.imshow(normalized_samples[i][64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_dict = {'train':train_fnames, 'validation':valid_fnames, 'test1':test1_fnames, 'test2':test2_fnames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2143, 15)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_fnames), len(valid_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_and_save(dataset, mask_dir='brain_masks'):\n",
    "    fnames = fnames_dict[dataset]\n",
    "    for fn in fnames:\n",
    "        image = np.load(data_path/f'{parent_dataset}/{dataset}/raw_images/{fn.name}')\n",
    "        mask = np.load(data_path/f'{parent_dataset}/{dataset}/{mask_dir}/{fn.name}')\n",
    "        normalized_image = normalize_with_mask(image, mask)\n",
    "        np.save(data_path/f'{parent_dataset}/{dataset}/skull_stripped_v2/{fn.name}', normalized_image)\n",
    "        \n",
    "#     parallel(_save, fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_and_save('train', mask_dir='brain_atlas')\n",
    "strip_and_save('validation', mask_dir='brain_masks')\n",
    "if test1_ds: strip_and_save('test1')\n",
    "if test2_ds: strip_and_save('test2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_predictions(model, dl):\n",
    "#     res = []\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for xb,yb in progress_bar(dl):\n",
    "#             out = model(xb)\n",
    "#             out = to_detach(out)\n",
    "#             res.append(out)\n",
    "#     res = torch.cat([o.float() for o in res]) # converts to fp32 cat doesn't work with fp16\n",
    "#     return res\n",
    "\n",
    "# data1 = DataBunch.create(train_ds=train_ds, valid_ds=valid_ds, test_ds=test1_ds, bs=2)\n",
    "# data1.add_tfm(batch_to_half)\n",
    "# data2 = DataBunch.create(train_ds=train_ds, valid_ds=valid_ds, test_ds=test2_ds, bs=2)\n",
    "# data2.add_tfm(batch_to_half)\n",
    "\n",
    "# train_dl = data1.train_dl.new(shuffle=False)\n",
    "# valid_dl = data1.valid_dl.new(shuffle=False)\n",
    "# test1_dl = data1.test_dl.new(shuffle=False) if test1_ds else None\n",
    "# test2_dl = data2.test_dl.new(shuffle=False) if test2_ds else None\n",
    "\n",
    "# test1_dl, test2_dl\n",
    "\n",
    "# # my data copy path\n",
    "# data_path = Path('../../data/Segmentation_Dataset/')\n",
    "\n",
    "# train_fnames = data1.train_ds.img_fnames\n",
    "# valid_fnames = data1.valid_ds.img_fnames\n",
    "# test1_fnames = data1.test_ds.img_fnames if test1_ds else None \n",
    "# test2_fnames = data2.test_ds.img_fnames if test2_ds else None\n",
    "\n",
    "# learn.to_fp16();\n",
    "\n",
    "# # model predictions\n",
    "# # train_preds = get_predictions(learn.model, train_dl)\n",
    "# # valid_preds = get_predictions(learn.model, valid_dl)\n",
    "# test1_preds = get_predictions(learn.model, test1_dl) if test1_ds else None\n",
    "# test2_preds = get_predictions(learn.model, test2_dl) if test2_ds else None\n",
    "\n",
    "# # train_preds.shape, valid_preds.shape, \n",
    "# test1_preds.shape, test2_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_dataset = 'MR_Dataset'\n",
    "# # parent_dataset = 'CT_Dataset'\n",
    "\n",
    "# test1_preds.squeeze_(1), test2_preds.squeeze_(1);\n",
    "\n",
    "# test1_preds.shape, test2_preds.shape\n",
    "\n",
    "# probas = True\n",
    "# if not probas:\n",
    "#     test1_preds_np = to_np(test1_preds) > 0\n",
    "#     test2_preds_np = to_np(test2_preds) > 0\n",
    "# else:\n",
    "#     test1_preds_np = to_np(torch.sigmoid(test1_preds)) \n",
    "#     test2_preds_np = to_np(torch.sigmoid(test2_preds))\n",
    "\n",
    "# test1_preds.shape, test2_preds.shape\n",
    "\n",
    "# is_tl = False\n",
    "# tl_str = 'notl' if not is_tl else 'tl'\n",
    "\n",
    "# p1 = (data_path/parent_dataset/f'test1/{model_name}_{tl_str}_ventricle_probas')\n",
    "# p2 = (data_path/parent_dataset/f'test2/{model_name}_{tl_str}_ventricle_probas')\n",
    "\n",
    "# p1\n",
    "\n",
    "# os.makedirs(p1, exist_ok=True)\n",
    "# os.makedirs(p2, exist_ok=True)\n",
    "\n",
    "# plt.imshow(test2_preds_np[8][64])\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# for o, pred in tqdm_notebook(zip(test1_fnames, test1_preds_np)):\n",
    "#     np.save(p1/o.name, pred)\n",
    "\n",
    "# for o, pred in tqdm_notebook(zip(test2_fnames, test2_preds_np)):\n",
    "#     np.save(p2/o.name, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collect_masks(dl): return torch.cat([to_cpu(yb) for _, yb in dl])\n",
    "\n",
    "# # human annotated masks\n",
    "# train_masks = collect_masks(train_dl)\n",
    "# valid_masks = collect_masks(valid_dl)\n",
    "# test1_masks = collect_masks(test1_dl) if test1_ds else None\n",
    "# test2_masks = collect_masks(test2_dl) if test2_ds else None\n",
    "\n",
    "# for masks in (train_masks, valid_masks, test1_masks, test2_masks):\n",
    "#     masks.unsqueeze_(1)\n",
    "\n",
    "# train_masks.shape, valid_masks.shape, test1_masks.shape, test2_masks.shape\n",
    "\n",
    "# def load_atlas(path, fnames):\n",
    "#     return torch.cat([torch.tensor(np.load(path/fn.name))[None] for fn in fnames])\n",
    "\n",
    "# train_atlas_path = (data_path/f'{parent_dataset}/train/brain_atlas')\n",
    "# valid_atlas_path = (data_path/f'{parent_dataset}/validation/brain_atlas')\n",
    "# test1_atlas_path = (data_path/f'{parent_dataset}/test1/brain_atlas')\n",
    "# test2_atlas_path = (data_path/f'{parent_dataset}/test2/brain_atlas')\n",
    "\n",
    "# # machine annotated masks\n",
    "# train_atlas = load_atlas(train_atlas_path, train_fnames)\n",
    "# valid_atlas = load_atlas(valid_atlas_path, valid_fnames)\n",
    "# test1_atlas = load_atlas(test1_atlas_path, test1_fnames)\n",
    "# test2_atlas = load_atlas(test2_atlas_path, test2_fnames)\n",
    "\n",
    "# for masks in (train_atlas, valid_atlas, test1_atlas, test2_atlas):\n",
    "#     masks.unsqueeze_(1)\n",
    "\n",
    "# train_atlas.shape, valid_atlas.shape, test1_atlas.shape, test2_atlas.shape\n",
    "\n",
    "# image_no=5\n",
    "# slice_no=64\n",
    "# ImageSegment(train_preds[image_no, :, slice_no] > 0)\n",
    "\n",
    "# image_no=5\n",
    "# slice_no=64\n",
    "# ImageSegment(train_masks[image_no, :, slice_no] > 0)\n",
    "\n",
    "# image_no=5\n",
    "# slice_no=64\n",
    "# ImageSegment(train_atlas[image_no, :, slice_no] > 0)\n",
    "\n",
    "# # deep learning performance\n",
    "# train_preds_score = dice_score(train_preds, train_masks)\n",
    "# valid_preds_score = dice_score(valid_preds, valid_masks)\n",
    "# test1_preds_score = dice_score(test1_preds, test1_masks)\n",
    "# test2_preds_score = dice_score(test2_preds, test2_masks)\n",
    "\n",
    "# train_preds_score, valid_preds_score, test1_preds_score, test2_preds_score\n",
    "\n",
    "# # atlas performance\n",
    "# train_atlas_score = dice_score(train_atlas, train_masks)\n",
    "# valid_atlas_score = dice_score(valid_atlas, valid_masks)\n",
    "# test1_atlas_score = dice_score(test1_atlas, test1_masks)\n",
    "# test2_atlas_score = dice_score(test2_atlas, test2_masks)\n",
    "\n",
    "# train_atlas_score, valid_atlas_score, test1_atlas_score, test2_atlas_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ventricle",
   "language": "python",
   "name": "ventricle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
