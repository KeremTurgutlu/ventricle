{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model predictions for best models trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.script import *\n",
    "\n",
    "from data_utils import *\n",
    "from models import *\n",
    "from learn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['notl_brain_mr', 'notl_brain_ct', 'atlas_brain_mr', 'notl_ventricle_mr', 'notl_ventricle_ct', 'atlas_ventricle_mr'])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the datasets: \n",
    "\n",
    "- **MR_Dataset (Brain):** `notl_brain_mr`\n",
    "- **CT_Dataset (Brain):** `notl_brain_ct`,\n",
    "- **MR_Dataset (Ventricle):** `notl_ventricle_mr`,\n",
    "- **CT_Dataset (Ventricle):** `notl_ventricle_ct`\n",
    "- **Atlas_Dataset (Brain):** `atlas_brain_mr`\n",
    "- **Atlas_Dataset (Ventricle):** `atlas_ventricle_mr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'notl_ventricle_mr'\n",
    "f = data_dict[data_name]\n",
    "train_paths, valid_paths, test1_paths, test2_paths = f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MRI_3D_Dataset(*train_paths)\n",
    "valid_ds = MRI_3D_Dataset(*valid_paths)\n",
    "test1_ds = MRI_3D_Dataset(*test1_paths) if test1_paths else None\n",
    "test2_ds = MRI_3D_Dataset(*test2_paths) if test2_paths else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "data = DataBunch.create(train_ds=train_ds, valid_ds=valid_ds, bs=bs)\n",
    "test1_dl = DeviceDataLoader(DataLoader(test1_ds, batch_size=bs), device=data.device) if test1_ds else None\n",
    "test2_dl = DeviceDataLoader(DataLoader(test2_ds, batch_size=bs), device=data.device) if test2_ds else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'baseline11'\n",
    "f = experiment_model_dict[model_name]; m = f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test2_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the model types: \n",
    "\n",
    "- **MR_Dataset (Brain) NOTL :** `notl_brain_mr_models`\n",
    "- **MR_Dataset (Brain) TL :** `tl_brain_mr_models`\n",
    "\n",
    "- **CT_Dataset (Brain) NOTL:** `notl_brain_ct_models`,\n",
    "- **CT_Dataset (Brain) TL:** `tl_brain_ct_models`,\n",
    "\n",
    "- **MR_Dataset (Ventricle) NOTL:** `notl_ventricle_mr_models`,\n",
    "- **MR_Dataset (Ventricle) TL:** `tl_ventricle_mr_models`,\n",
    "\n",
    "- **CT_Dataset (Ventricle) NOTL:** `notl_ventricle_ct_models`\n",
    "- **CT_Dataset (Ventricle) TL:** `tl_ventricle_ct_models`\n",
    "\n",
    "- **Atlas_Dataset (Brain):** `atlas_brain_mr_models`\n",
    "\n",
    "- **Atlas_Dataset (Ventricle):** `atlas_ventricle_mr_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = 'dice'\n",
    "model_dir = 'tl_ventricle_ct_models'\n",
    "learn = Learner(data=data, model=m, callbacks=[], callback_fns=[], model_dir=model_dir)\n",
    "learn.loss_func = {'dice':dice_loss, 'bce':BCEWithLogitsFlat(), 'mixed':None}[loss_func] \n",
    "learn.metrics = [dice_score]\n",
    "learn.to_fp16();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_11_20_SAMPLES.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_4.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_2.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_6.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_11_60_SAMPLES.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_10.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_9.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_5.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Samples10_Baseline_11.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_3.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_11_5_SAMPLES.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_1.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Samples20_Baseline_11.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_7.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_11.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_11_10_SAMPLES.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Baseline_11_40_SAMPLES.pth'),\n",
       " PosixPath('tl_ventricle_ct_models/best_of_TL_Ventricle_CT_Samples50_Baseline_11.pth')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(sorted((learn.path/learn.model_dir).ls(), key=lambda o:int(o.stem.split('_')[-1])))\n",
    "except:\n",
    "    (display((learn.path/learn.model_dir).ls()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('best_of_TL_Ventricle_CT_Baseline_11');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1865716, tensor(0.8135)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate(learn.data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fp32();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18914835, tensor(0.8109)]\n"
     ]
    }
   ],
   "source": [
    "if test1_dl: print(learn.validate(test1_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24176042, tensor(0.7583)]\n"
     ]
    }
   ],
   "source": [
    "if test2_dl: print(learn.validate(test2_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# path = Path(\"logs/\"); path.ls()\n",
    "\n",
    "# path = Path(f\"logs/{model_dir}\"); path.ls()\n",
    "\n",
    "# log_df = pd.read_csv(path/'ATLAS_Brain_MR_Baseline_11.csv')\n",
    "\n",
    "# log_df\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "# ax.set_title(f'Loss: {loss_func}')\n",
    "# ax.set_xlabel(\"Epoch\")\n",
    "# ax.plot(log_df['train_loss'])\n",
    "# ax.plot(log_df['valid_loss']);\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "# ax.set_title(f\"Dice Score: {np.round(log_df['dice_score'].max(), 2)}\")\n",
    "# ax.set_xlabel(\"Epoch\")\n",
    "# plt.plot(log_df['dice_score']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def to_int8(a): return a.astype(np.uint8)\n",
    "\n",
    "# data1 = DataBunch.create(train_ds=train_ds, valid_ds=valid_ds, test_ds=test1_ds, bs=3)\n",
    "# data2 = DataBunch.create(train_ds=train_ds, valid_ds=valid_ds, test_ds=test2_ds, bs=3)\n",
    "\n",
    "# train_fnames = data1.train_ds.img_fnames\n",
    "# valid_fnames = data1.valid_ds.img_fnames\n",
    "# test1_fnames = data1.test_ds.img_fnames\n",
    "# test2_fnames = data1.test_ds.img_fnames\n",
    "\n",
    "# len(train_fnames), len(valid_fnames), len(test1_fnames), len(test2_fnames)\n",
    "\n",
    "# train_dl = data1.train_dl.new(shuffle=False)\n",
    "# valid_dl = data1.valid_dl.new(shuffle=False)\n",
    "# test1_dl = data1.test_dl.new(shuffle=False)\n",
    "# test2_dl = data2.test_dl.new(shuffle=False)\n",
    "\n",
    "# learn.to_fp16();\n",
    "\n",
    "# # # training\n",
    "# # images, preds, masks = get_img_pred_masks(learn, train_dl)\n",
    "\n",
    "# # # validation\n",
    "# # images, preds, masks = get_img_pred_masks(learn, valid_dl)\n",
    "\n",
    "# # # test1\n",
    "# # images, preds, masks = get_img_pred_masks(learn, test1_dl)\n",
    "\n",
    "# # # test2\n",
    "# # images, preds, masks = get_img_pred_masks(learn, test2_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Deep Learning with Atlas\n",
    "\n",
    "Skull strip train, valid, test1 and test2\n",
    "\n",
    "- Compare with atlas masks\n",
    "- RuntimeError: _th_cat is not implemented for type torch.HalfTensor\n",
    "- Save to data_path/**/skull_stripped_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_targs(dl):\n",
    "    test_preds, test_targs = get_preds(learn.model, dl)\n",
    "    test_preds.squeeze_(1); test_preds.sigmoid_();\n",
    "    return test_preds, test_targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_preds, test1_targs = get_preds_targs(test1_dl)\n",
    "test2_preds, test2_targs = get_preds_targs(test2_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9, 128, 256, 256]), torch.Size([9, 128, 256, 256]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_preds.shape, test1_targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18, 128, 256, 256]), torch.Size([18, 128, 256, 256]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_preds.shape, test2_targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(10,20))\n",
    "ImageSegment(test1_preds[0][70][None,...]).show(ax=ax[0], alpha=1, cmap='tab20', title='pred')\n",
    "ImageSegment(test1_targs[0][70][None,...]).show(ax=ax[1], alpha=1, cmap='tab20', title='targ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(\"/home/turgutluk/data/Segmentation_Dataset/CT_Dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_savedir = save_path/'test1/ventricle_preds'; os.makedirs(test1_savedir, exist_ok=True)\n",
    "test2_savedir = save_path/'test2/ventricle_preds'; os.makedirs(test2_savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle([test1_preds, test1_targs], test1_savedir/f'{model_name}_preds.pkl')\n",
    "pd.to_pickle([test2_preds, test2_targs], test2_savedir/f'{model_name}_preds.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skull Stripping v2\n",
    "\n",
    "- Human annotated brain masks will be used where possible\n",
    "- \"First, we normalize each modality of each patient independently by subtracting the mean and dividing by the standard deviation of the brain region. We then clip the resulting images at [−5, 5] to remove outliers and subsequently rescale to [0, 1], with the non-brain region being set to 0.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dataset = 'MR_Dataset_Atlas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_path/f'{parent_dataset}/train/skull_stripped_v2', exist_ok=True)\n",
    "os.makedirs(data_path/f'{parent_dataset}/validation/skull_stripped_v2', exist_ok=True)\n",
    "if test1_ds: os.makedirs(data_path/f'{parent_dataset}/test1/skull_stripped_v2', exist_ok=True) \n",
    "if test2_ds: os.makedirs(data_path/f'{parent_dataset}/test2/skull_stripped_v2', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../data/Segmentation_Dataset/MR_Dataset_Atlas/train/raw_images/BrainMets-UCSF-00001_19990425000000.000_2.16.840_579.6972_RTst_1999-04-25_000000_._MR.Bias.Corrected,.axial.t1.g_n1__00000_MR.npy'),\n",
       " PosixPath('../../data/Segmentation_Dataset/MR_Dataset_Atlas/train/raw_images/BrainMets-UCSF-00004_19970413000000.000_2.16.840_482.7049_RTst_1997-04-13_000000_._MR.Bias.Corrected,.axial_n1__00000_MR.npy')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((data_path/f'{parent_dataset}/train/raw_images').ls())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../data/Segmentation_Dataset/MR_Dataset_Atlas/train/brain_atlas/BrainMets-UCSF-00001_19990425000000.000_2.16.840_579.6972_RTst_1999-04-25_000000_._MR.Bias.Corrected,.axial.t1.g_n1__00000_MR.npy'),\n",
       " PosixPath('../../data/Segmentation_Dataset/MR_Dataset_Atlas/train/brain_atlas/BrainMets-UCSF-00004_19970413000000.000_2.16.840_482.7049_RTst_1997-04-13_000000_._MR.Bias.Corrected,.axial_n1__00000_MR.npy')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((data_path/f'{parent_dataset}/train/brain_atlas').ls())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_images = [np.load(fn) for fn in (data_path/f'{parent_dataset}/train/raw_images').ls()]\n",
    "# # brain_masks = [np.load(fn) for fn in (data_path/f'{parent_dataset}/train/brain_masks').ls()]\n",
    "# brain_masks = [np.load(fn) for fn in (data_path/f'{parent_dataset}/train/brain_atlas').ls()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(raw_images), len(brain_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pixel density plot of different scans\n",
    "for i in range(10):\n",
    "    sns.distplot(np.clip(raw_images[i][50:70].flatten(), 0, 400), hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_with_mask(image, mask):\n",
    "    \"\"\"\n",
    "    First, we normalize each modality of each patient \n",
    "    independently by subtracting the mean and dividing by the standard deviation of the brain region.\n",
    "    We then clip the resulting images at [−5, 5] to remove outliers and subsequently rescale to [0, 1],\n",
    "    with the non-brain region being set to 0.\n",
    "    \"\"\"\n",
    "    mx = np.ma.masked_array(image, mask=1-mask) # True for places that are masked, we want to exclude non-brain\n",
    "    mean, std = mx.mean(), mx.std()\n",
    "    return np.clip((image - mean) / std, -5, 5)*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_samples = [normalize_with_mask(image, mask) for image, mask in zip(raw_images[:10], brain_masks[:10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel density plot of normalized scans\n",
    "for i in range(10):\n",
    "    sns.distplot(np.clip(normalized_samples[i][50:70].flatten(), -2, 2), hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize=(15,6))\n",
    "for i,ax in enumerate(axes.flatten()): ax.imshow(normalized_samples[i][64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_dict = {'train':train_fnames, 'validation':valid_fnames, 'test1':test1_fnames, 'test2':test2_fnames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2143, 15)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_fnames), len(valid_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_and_save(dataset, mask_dir='brain_masks'):\n",
    "    fnames = fnames_dict[dataset]\n",
    "    for fn in fnames:\n",
    "        image = np.load(data_path/f'{parent_dataset}/{dataset}/raw_images/{fn.name}')\n",
    "        mask = np.load(data_path/f'{parent_dataset}/{dataset}/{mask_dir}/{fn.name}')\n",
    "        normalized_image = normalize_with_mask(image, mask)\n",
    "        np.save(data_path/f'{parent_dataset}/{dataset}/skull_stripped_v2/{fn.name}', normalized_image)\n",
    "        \n",
    "#     parallel(_save, fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_and_save('train', mask_dir='brain_atlas')\n",
    "strip_and_save('validation', mask_dir='brain_masks')\n",
    "if test1_ds: strip_and_save('test1')\n",
    "if test2_ds: strip_and_save('test2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_predictions(model, dl):\n",
    "#     res = []\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for xb,yb in progress_bar(dl):\n",
    "#             out = model(xb)\n",
    "#             out = to_detach(out)\n",
    "#             res.append(out)\n",
    "#     res = torch.cat([o.float() for o in res]) # converts to fp32 cat doesn't work with fp16\n",
    "#     return res\n",
    "\n",
    "# data1 = DataBunch.create(train_ds=train_ds, valid_ds=valid_ds, test_ds=test1_ds, bs=2)\n",
    "# data1.add_tfm(batch_to_half)\n",
    "# data2 = DataBunch.create(train_ds=train_ds, valid_ds=valid_ds, test_ds=test2_ds, bs=2)\n",
    "# data2.add_tfm(batch_to_half)\n",
    "\n",
    "# train_dl = data1.train_dl.new(shuffle=False)\n",
    "# valid_dl = data1.valid_dl.new(shuffle=False)\n",
    "# test1_dl = data1.test_dl.new(shuffle=False) if test1_ds else None\n",
    "# test2_dl = data2.test_dl.new(shuffle=False) if test2_ds else None\n",
    "\n",
    "# test1_dl, test2_dl\n",
    "\n",
    "# # my data copy path\n",
    "# data_path = Path('../../data/Segmentation_Dataset/')\n",
    "\n",
    "# train_fnames = data1.train_ds.img_fnames\n",
    "# valid_fnames = data1.valid_ds.img_fnames\n",
    "# test1_fnames = data1.test_ds.img_fnames if test1_ds else None \n",
    "# test2_fnames = data2.test_ds.img_fnames if test2_ds else None\n",
    "\n",
    "# learn.to_fp16();\n",
    "\n",
    "# # model predictions\n",
    "# # train_preds = get_predictions(learn.model, train_dl)\n",
    "# # valid_preds = get_predictions(learn.model, valid_dl)\n",
    "# test1_preds = get_predictions(learn.model, test1_dl) if test1_ds else None\n",
    "# test2_preds = get_predictions(learn.model, test2_dl) if test2_ds else None\n",
    "\n",
    "# # train_preds.shape, valid_preds.shape, \n",
    "# test1_preds.shape, test2_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_dataset = 'MR_Dataset'\n",
    "# # parent_dataset = 'CT_Dataset'\n",
    "\n",
    "# test1_preds.squeeze_(1), test2_preds.squeeze_(1);\n",
    "\n",
    "# test1_preds.shape, test2_preds.shape\n",
    "\n",
    "# probas = True\n",
    "# if not probas:\n",
    "#     test1_preds_np = to_np(test1_preds) > 0\n",
    "#     test2_preds_np = to_np(test2_preds) > 0\n",
    "# else:\n",
    "#     test1_preds_np = to_np(torch.sigmoid(test1_preds)) \n",
    "#     test2_preds_np = to_np(torch.sigmoid(test2_preds))\n",
    "\n",
    "# test1_preds.shape, test2_preds.shape\n",
    "\n",
    "# is_tl = False\n",
    "# tl_str = 'notl' if not is_tl else 'tl'\n",
    "\n",
    "# p1 = (data_path/parent_dataset/f'test1/{model_name}_{tl_str}_ventricle_probas')\n",
    "# p2 = (data_path/parent_dataset/f'test2/{model_name}_{tl_str}_ventricle_probas')\n",
    "\n",
    "# p1\n",
    "\n",
    "# os.makedirs(p1, exist_ok=True)\n",
    "# os.makedirs(p2, exist_ok=True)\n",
    "\n",
    "# plt.imshow(test2_preds_np[8][64])\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# for o, pred in tqdm_notebook(zip(test1_fnames, test1_preds_np)):\n",
    "#     np.save(p1/o.name, pred)\n",
    "\n",
    "# for o, pred in tqdm_notebook(zip(test2_fnames, test2_preds_np)):\n",
    "#     np.save(p2/o.name, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collect_masks(dl): return torch.cat([to_cpu(yb) for _, yb in dl])\n",
    "\n",
    "# # human annotated masks\n",
    "# train_masks = collect_masks(train_dl)\n",
    "# valid_masks = collect_masks(valid_dl)\n",
    "# test1_masks = collect_masks(test1_dl) if test1_ds else None\n",
    "# test2_masks = collect_masks(test2_dl) if test2_ds else None\n",
    "\n",
    "# for masks in (train_masks, valid_masks, test1_masks, test2_masks):\n",
    "#     masks.unsqueeze_(1)\n",
    "\n",
    "# train_masks.shape, valid_masks.shape, test1_masks.shape, test2_masks.shape\n",
    "\n",
    "# def load_atlas(path, fnames):\n",
    "#     return torch.cat([torch.tensor(np.load(path/fn.name))[None] for fn in fnames])\n",
    "\n",
    "# train_atlas_path = (data_path/f'{parent_dataset}/train/brain_atlas')\n",
    "# valid_atlas_path = (data_path/f'{parent_dataset}/validation/brain_atlas')\n",
    "# test1_atlas_path = (data_path/f'{parent_dataset}/test1/brain_atlas')\n",
    "# test2_atlas_path = (data_path/f'{parent_dataset}/test2/brain_atlas')\n",
    "\n",
    "# # machine annotated masks\n",
    "# train_atlas = load_atlas(train_atlas_path, train_fnames)\n",
    "# valid_atlas = load_atlas(valid_atlas_path, valid_fnames)\n",
    "# test1_atlas = load_atlas(test1_atlas_path, test1_fnames)\n",
    "# test2_atlas = load_atlas(test2_atlas_path, test2_fnames)\n",
    "\n",
    "# for masks in (train_atlas, valid_atlas, test1_atlas, test2_atlas):\n",
    "#     masks.unsqueeze_(1)\n",
    "\n",
    "# train_atlas.shape, valid_atlas.shape, test1_atlas.shape, test2_atlas.shape\n",
    "\n",
    "# image_no=5\n",
    "# slice_no=64\n",
    "# ImageSegment(train_preds[image_no, :, slice_no] > 0)\n",
    "\n",
    "# image_no=5\n",
    "# slice_no=64\n",
    "# ImageSegment(train_masks[image_no, :, slice_no] > 0)\n",
    "\n",
    "# image_no=5\n",
    "# slice_no=64\n",
    "# ImageSegment(train_atlas[image_no, :, slice_no] > 0)\n",
    "\n",
    "# # deep learning performance\n",
    "# train_preds_score = dice_score(train_preds, train_masks)\n",
    "# valid_preds_score = dice_score(valid_preds, valid_masks)\n",
    "# test1_preds_score = dice_score(test1_preds, test1_masks)\n",
    "# test2_preds_score = dice_score(test2_preds, test2_masks)\n",
    "\n",
    "# train_preds_score, valid_preds_score, test1_preds_score, test2_preds_score\n",
    "\n",
    "# # atlas performance\n",
    "# train_atlas_score = dice_score(train_atlas, train_masks)\n",
    "# valid_atlas_score = dice_score(valid_atlas, valid_masks)\n",
    "# test1_atlas_score = dice_score(test1_atlas, test1_masks)\n",
    "# test2_atlas_score = dice_score(test2_atlas, test2_masks)\n",
    "\n",
    "# train_atlas_score, valid_atlas_score, test1_atlas_score, test2_atlas_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_fastai]",
   "language": "python",
   "name": "conda-env-my_fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
